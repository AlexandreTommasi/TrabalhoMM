{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, vfx\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refletir_imagem(frame):\n",
    "    \"\"\"\n",
    "    Reflete horizontalmente o frame.\n",
    "    \"\"\"\n",
    "    return frame[:, ::-1]\n",
    "\n",
    "def aplicar_reflexao(video):\n",
    "    \"\"\"\n",
    "    Aplica a reflexão horizontal alternada a cada 20 segundos.\n",
    "    \"\"\"\n",
    "    clips = []\n",
    "    for start in np.arange(0, video.duration, 20):\n",
    "        end = min(start + 20, video.duration)\n",
    "        subclip = video.subclip(start, end)\n",
    "        if int(start // 20) % 2 == 1:  # Alternar reflexão\n",
    "            subclip = subclip.fl_image(refletir_imagem)\n",
    "        clips.append(subclip)\n",
    "    return concatenate_videoclips(clips)\n",
    "\n",
    "# Carregar o vídeo e aplicar reflexão\n",
    "input_video_path = \"video.mp4\"\n",
    "video = VideoFileClip(input_video_path)\n",
    "video_refletido = aplicar_reflexao(video)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduzir_som_e_ficar_mudo(clip):\n",
    "    \"\"\"\n",
    "    Reduz gradativamente o volume a cada 30 segundos e zera o som nos últimos 10 segundos.\n",
    "    \"\"\"\n",
    "    audio = clip.audio\n",
    "    if audio is None:\n",
    "        print(\"Aviso: O vídeo não possui áudio para manipular.\")\n",
    "        return clip  # Retorna o vídeo original se não houver áudio\n",
    "\n",
    "    duration = clip.duration\n",
    "    fade_start = max(0, duration - 30)  # Início da redução gradativa\n",
    "    mute_start = max(0, duration - 10)  # Início do silêncio total\n",
    "\n",
    "    def ajustar_volume(gf, t):\n",
    "        if np.isscalar(t):\n",
    "            # Para tempos únicos\n",
    "            if t >= mute_start:\n",
    "                return 0 * gf(t)  # Ficar mudo nos últimos 10 segundos\n",
    "            elif t >= fade_start:\n",
    "                return (1 - (t - fade_start) / 20) * gf(t)  # Redução gradual\n",
    "            else:\n",
    "                return gf(t)\n",
    "        else:\n",
    "            # Para arrays de tempo\n",
    "            fator = np.where(\n",
    "                t >= mute_start, \n",
    "                0,  # Silêncio total\n",
    "                np.where(t >= fade_start, 1 - (t - fade_start) / 20, 1)  # Gradual\n",
    "            )\n",
    "            return fator[:, None] * gf(t)\n",
    "\n",
    "    # Aplicar a redução de som\n",
    "    audio = audio.fl(ajustar_volume, keep_duration=True)\n",
    "    return clip.set_audio(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                                   \n",
      "\u001b[A                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video video_final.mp4.\n",
      "MoviePy - Writing audio in video_finalTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \n",
      "\u001b[A                                                                     \n",
      "\u001b[A                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video video_final.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "\u001b[A                                                                     \n",
      "\u001b[A                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready video_final.mp4\n"
     ]
    }
   ],
   "source": [
    "def cortar_e_inserir(video):\n",
    "    \"\"\"\n",
    "    Corta o segmento do segundo 60 ao 80 e o insere ao final.\n",
    "    \"\"\"\n",
    "    if video.duration > 80:\n",
    "        corte = video.subclip(60, 80)\n",
    "        video_final = concatenate_videoclips([video, corte])\n",
    "    else:\n",
    "        video_final = video\n",
    "    return video_final\n",
    "\n",
    "# Aplicar a redução de som\n",
    "video_som_reduzido = reduzir_som_e_ficar_mudo(video_refletido)\n",
    "\n",
    "# Continuar com o processamento final\n",
    "video_final = cortar_e_inserir(video_som_reduzido)\n",
    "\n",
    "# Salvar o vídeo final\n",
    "output_video_path = \"video_final.mp4\"\n",
    "video_final.write_videofile(\"video_final.mp4\", codec=\"libx264\", audio_codec=\"aac\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
